# -*- coding: utf-8 -*-
"""AI_Week_2_Best_Fit_CV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sfv1vs7FEii9D3ubzZRQErNItfDxwfak
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd

lr = LogisticRegression()
#dict of hyperparameters we wish to test
parameters = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}
#input the lr object and parameters list
cv = GridSearchCV(lr, parameters, cv=5)
#cv stands for cross validation which helps deal with overfit, runs 5 times with smaller slices of the data
data = pd.read_csv('modifiedIris2Classes.csv')

cv.fit(data[['petal width (cm)', 'petal length (cm)','sepal length (cm)', 'sepal width (cm)']], data['target'])

data.head()

def print_results(results):
  means = results.cv_results_['mean_test_score']
  stds = results.cv_results_['std_test_score']
  for mean,std,params in zip(means,stds,results.cv_results_['params']):
    print(f'{(mean,6)} + or - {(std,6)} for the {params}')
print_results(cv)

cv.best_params_

candata = pd.read_csv('cancer.csv')
candata.head()

clr = LogisticRegression()
cparameters = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}
ccv = GridSearchCV(clr, parameters, cv=5)
ccv.fit(candata[['Clump Thickness', 'UofCSize','UofCShape', 'Mitoses', 'Normal Nucleoli', 'Bare Nuclei']], candata['Class'])
print_results(ccv)
ccv.best_params_

sns.heatmap(candata.corr(), annot=True)
x_train, x_test, y_train, y_test = train_test_split(candata[['Clump Thickness', 'UofCSize','UofCShape', 'Mitoses', 'Normal Nucleoli', 'Bare Nuclei']],
                                                    candata['Class'], test_size=0.2, random_state=42)